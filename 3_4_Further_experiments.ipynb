{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3lRQ--2Cum0",
    "outputId": "be0f27fd-3613-4a47-fd36-c46d48e3adf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nBAe6xXsCxib"
   },
   "outputs": [],
   "source": [
    "# Encoding the integer sequences into a binary matrix\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1.\n",
    "  return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPT3RJo7C8zp"
   },
   "outputs": [],
   "source": [
    "# also vectorize your labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xVSzibNZDA6E"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J7AL6_o5DESD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def reset_random_seeds(SEED = 42):\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VNDjZ3V5DM97"
   },
   "outputs": [],
   "source": [
    "def create_and_train_model(hidden_layers=2,\n",
    "                           hidden_units=16, \n",
    "                           loss_function='binary_crossentropy',\n",
    "                           activation_function='relu'):\n",
    "  \n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "\n",
    "  for i in range(hidden_layers - 1):\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    " \n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss=loss_function,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "  results = model.evaluate(x_test, y_test)\n",
    "\n",
    "  return \"[hidden_layers=%d, hidden_units=%d, loss_function=%s, \" \\\n",
    "          \"activation_function=%s] => loss: %.4f - accuracy: %.4f\" % (\n",
    "          hidden_layers, hidden_units, loss_function, activation_function,\n",
    "          results[0], results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SmHGvWh6DQNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 9s 5ms/step - loss: 0.5156 - accuracy: 0.7508\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.9115\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.9310\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9414\n",
      "782/782 [==============================] - 1s 582us/step - loss: 0.2958 - accuracy: 0.8808\n",
      "[hidden_layers=1, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2958 - accuracy: 0.8808\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5497 - accuracy: 0.7407\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.9071\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2027 - accuracy: 0.9301\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1624 - accuracy: 0.9439\n",
      "782/782 [==============================] - 1s 585us/step - loss: 0.3586 - accuracy: 0.8603\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.3586 - accuracy: 0.8603\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5544 - accuracy: 0.7296\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.9147\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 0.9330\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9445\n",
      "782/782 [==============================] - 1s 591us/step - loss: 0.3192 - accuracy: 0.8770\n",
      "[hidden_layers=3, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.3192 - accuracy: 0.8770\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5813 - accuracy: 0.7326\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2753 - accuracy: 0.9028\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9311\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9448\n",
      "782/782 [==============================] - 1s 606us/step - loss: 0.3049 - accuracy: 0.8818\n",
      "[hidden_layers=4, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.3049 - accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "# You used two hidden layers. Try using one or three hidden layers, \n",
    "# and see how doing so affects validation and test accuracy.\n",
    "\n",
    "for value in [1, 2, 3, 4]:\n",
    "  res = create_and_train_model(hidden_layers=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEHs9YwZDTHR",
    "outputId": "62383eec-b083-465d-fb18-c70dcad0b8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.6265 - accuracy: 0.7082\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.8807\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3115 - accuracy: 0.9098\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.9242\n",
      "782/782 [==============================] - 1s 575us/step - loss: 0.2907 - accuracy: 0.8906\n",
      "[hidden_layers=2, hidden_units=4, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2907 - accuracy: 0.8906\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.7319\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.9019\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9244\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9378\n",
      "782/782 [==============================] - 1s 581us/step - loss: 0.2858 - accuracy: 0.8841\n",
      "[hidden_layers=2, hidden_units=8, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2858 - accuracy: 0.8841\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5657 - accuracy: 0.7368\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2852 - accuracy: 0.9059\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2075 - accuracy: 0.9284\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9414\n",
      "782/782 [==============================] - 1s 598us/step - loss: 0.2895 - accuracy: 0.8849\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2895 - accuracy: 0.8849\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7422\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2442 - accuracy: 0.9109\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.9338\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1558 - accuracy: 0.9417\n",
      "782/782 [==============================] - 1s 600us/step - loss: 0.3352 - accuracy: 0.8728\n",
      "[hidden_layers=2, hidden_units=32, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.3352 - accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "# Try using layers with more hidden units or fewer hidden units: \n",
    "# 32 units, 64 units, and so on.\n",
    "\n",
    "for value in [4, 8, 16, 32]:\n",
    "  res = create_and_train_model(hidden_units=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQog_ia8D_yM",
    "outputId": "3aac1a60-a5ae-4889-f350-0869fb20a214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5378 - accuracy: 0.7433\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.9112\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9314\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1591 - accuracy: 0.9450\n",
      "782/782 [==============================] - 1s 587us/step - loss: 0.2978 - accuracy: 0.8835\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2978 - accuracy: 0.8835\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.7405\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9158\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9355\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9498\n",
      "782/782 [==============================] - 1s 586us/step - loss: 0.0867 - accuracy: 0.8832\n",
      "[hidden_layers=2, hidden_units=16, loss_function=mse, activation_function=relu] => loss: 0.0867 - accuracy: 0.8832\n"
     ]
    }
   ],
   "source": [
    "# Try using the mse loss function instead of binary_crossentropy.\n",
    "\n",
    "for value in ['binary_crossentropy', 'mse']:\n",
    "  res = create_and_train_model(loss_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PBCyLqaUEGXi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.7509\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2551 - accuracy: 0.9138\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9362\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9461\n",
      "782/782 [==============================] - 1s 586us/step - loss: 0.3145 - accuracy: 0.87720s - loss: 0.3210 - accura\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.3145 - accuracy: 0.8772\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5090 - accuracy: 0.7615\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9229\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1745 - accuracy: 0.9388\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9525\n",
      "782/782 [==============================] - 1s 568us/step - loss: 0.3445 - accuracy: 0.8708\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=tanh] => loss: 0.3445 - accuracy: 0.8708\n"
     ]
    }
   ],
   "source": [
    "# Try using the tanh activation (an activation that was popular in \n",
    "# the early days of neural networks) instead of relu.\n",
    "\n",
    "for value in ['relu', 'tanh']:\n",
    "  res = create_and_train_model(activation_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4-Further experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
