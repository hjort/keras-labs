{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b772aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Reuters dataset\n",
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c234328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffe4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a built-in way to do this in Keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b14baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def reset_random_seeds(SEED = 42):\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffa07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def create_and_train_model(hidden_layers=2,\n",
    "                           hidden_units=64,\n",
    "                           loss_function='categorical_crossentropy',\n",
    "                           activation_function='relu'):\n",
    "  \n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "\n",
    "  for i in range(hidden_layers - 1):\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    " \n",
    "  model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss=loss_function,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train, one_hot_train_labels, epochs=8, batch_size=512)\n",
    "\n",
    "  results = model.evaluate(x_test, one_hot_test_labels)\n",
    "\n",
    "  return \"[hidden_layers=%d, hidden_units=%d, loss_function=%s, \" \\\n",
    "          \"activation_function=%s] => loss: %.4f - accuracy: %.4f\" % (\n",
    "          hidden_layers, hidden_units, loss_function, activation_function,\n",
    "          results[0], results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57667e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18/18 [==============================] - 1s 6ms/step - loss: 3.6341 - accuracy: 0.2622\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.8315 - accuracy: 0.3715\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1837 - accuracy: 0.4244\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7659 - accuracy: 0.5994\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5142 - accuracy: 0.6910\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2997 - accuracy: 0.7233\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1743 - accuracy: 0.7425\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0578 - accuracy: 0.7642\n",
      "71/71 [==============================] - 0s 609us/step - loss: 1.2579 - accuracy: 0.7177\n",
      "[hidden_layers=2, hidden_units=16, loss_function=categorical_crossentropy, activation_function=relu] => loss: 1.2579 - accuracy: 0.7177\n",
      "Epoch 1/8\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 3.3338 - accuracy: 0.3780\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.9042 - accuracy: 0.6348\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4361 - accuracy: 0.6867\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1457 - accuracy: 0.7548\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9647 - accuracy: 0.7882\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8297 - accuracy: 0.8190\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7140 - accuracy: 0.8428\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6094 - accuracy: 0.8679\n",
      "71/71 [==============================] - 0s 678us/step - loss: 1.0361 - accuracy: 0.7636\n",
      "[hidden_layers=2, hidden_units=32, loss_function=categorical_crossentropy, activation_function=relu] => loss: 1.0361 - accuracy: 0.7636\n",
      "Epoch 1/8\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 3.0132 - accuracy: 0.4254\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.3696 - accuracy: 0.7047\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9884 - accuracy: 0.7929\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7717 - accuracy: 0.8363\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5939 - accuracy: 0.8768\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4769 - accuracy: 0.9032\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3772 - accuracy: 0.9211\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3095 - accuracy: 0.9324\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9494 - accuracy: 0.7912\n",
      "[hidden_layers=2, hidden_units=64, loss_function=categorical_crossentropy, activation_function=relu] => loss: 0.9494 - accuracy: 0.7912\n",
      "Epoch 1/8\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 2.6974 - accuracy: 0.4739\n",
      "Epoch 2/8\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.1143 - accuracy: 0.7540\n",
      "Epoch 3/8\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7434 - accuracy: 0.8457\n",
      "Epoch 4/8\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5118 - accuracy: 0.8941\n",
      "Epoch 5/8\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3695 - accuracy: 0.9248\n",
      "Epoch 6/8\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.2808 - accuracy: 0.9394\n",
      "Epoch 7/8\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.2240 - accuracy: 0.9460\n",
      "Epoch 8/8\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.1886 - accuracy: 0.9499\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try using larger or smaller layers: 32 units, 128 units, and so on.\n",
    "\n",
    "for value in [16, 32, 64, 128]:\n",
    "  res = create_and_train_model(hidden_units=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# You used two hidden layers. Now try using a single hidden layer, or three hidden layers.\n",
    "\n",
    "for value in [1, 2, 3]:\n",
    "  res = create_and_train_model(hidden_layers=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b6d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
