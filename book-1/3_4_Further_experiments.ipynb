{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3lRQ--2Cum0",
    "outputId": "be0f27fd-3613-4a47-fd36-c46d48e3adf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nBAe6xXsCxib"
   },
   "outputs": [],
   "source": [
    "# Encoding the integer sequences into a binary matrix\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1.\n",
    "  return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPT3RJo7C8zp"
   },
   "outputs": [],
   "source": [
    "# also vectorize your labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J7AL6_o5DESD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def reset_random_seeds(SEED = 42):\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VNDjZ3V5DM97"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def create_and_train_model(hidden_layers=2,\n",
    "                           hidden_units=16, \n",
    "                           loss_function='binary_crossentropy',\n",
    "                           activation_function='relu'):\n",
    "  \n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "\n",
    "  for i in range(hidden_layers - 1):\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    " \n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss=loss_function,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "  results = model.evaluate(x_test, y_test)\n",
    "\n",
    "  return \"[hidden_layers=%d, hidden_units=%d, loss_function=%s, \" \\\n",
    "          \"activation_function=%s]\\n => loss: %.4f - accuracy: %.4f\\n\" % (\n",
    "          hidden_layers, hidden_units, loss_function, activation_function,\n",
    "          results[0], results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SmHGvWh6DQNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7559\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.9068\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2231 - accuracy: 0.9278\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9376\n",
      "782/782 [==============================] - 1s 582us/step - loss: 0.2799 - accuracy: 0.8893\n",
      "[hidden_layers=1, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2799 - accuracy: 0.8893\n",
      "\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 5ms/step - loss: 0.5503 - accuracy: 0.7416\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2740 - accuracy: 0.9051\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9311\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1658 - accuracy: 0.9412\n",
      "782/782 [==============================] - 1s 583us/step - loss: 0.2972 - accuracy: 0.8825\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2972 - accuracy: 0.8825\n",
      "\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7397\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.9072\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9310\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9470\n",
      "782/782 [==============================] - 1s 592us/step - loss: 0.2979 - accuracy: 0.8837\n",
      "[hidden_layers=3, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2979 - accuracy: 0.8837\n",
      "\n",
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5828 - accuracy: 0.7286\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2655 - accuracy: 0.9083\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.1892 - accuracy: 0.9333\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1591 - accuracy: 0.9415\n",
      "782/782 [==============================] - 1s 578us/step - loss: 0.3720 - accuracy: 0.8613\n",
      "[hidden_layers=4, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3720 - accuracy: 0.8613\n",
      "\n",
      "CPU times: user 48.3 s, sys: 3.71 s, total: 52 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# You used two hidden layers. Try using one or three hidden layers, \n",
    "# and see how doing so affects validation and test accuracy.\n",
    "# => best result: 2 hidden layers\n",
    "\n",
    "for value in [1, 2, 3, 4]:\n",
    "  res = create_and_train_model(hidden_layers=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEHs9YwZDTHR",
    "outputId": "62383eec-b083-465d-fb18-c70dcad0b8ab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Try using layers with more hidden units or fewer hidden units: \n",
    "# 32 units, 64 units, and so on.\n",
    "\n",
    "# => best result: ? hidden units\n",
    "\n",
    "for value in [4, 8, 16, 32]:\n",
    "  res = create_and_train_model(hidden_units=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQog_ia8D_yM",
    "outputId": "3aac1a60-a5ae-4889-f350-0869fb20a214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 6ms/step - loss: 0.5648 - accuracy: 0.7359\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.2894 - accuracy: 0.9024\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.2124 - accuracy: 0.9248\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.9412\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.2930 - accuracy: 0.8843\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu] => loss: 0.2930 - accuracy: 0.8843\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try using the mse loss function instead of binary_crossentropy.\n",
    "\n",
    "# => best result: ? loss function\n",
    "\n",
    "for value in ['binary_crossentropy', 'mse']:\n",
    "  res = create_and_train_model(loss_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBCyLqaUEGXi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Try using the tanh activation (an activation that was popular in \n",
    "# the early days of neural networks) instead of relu.\n",
    "\n",
    "# => best result: ? activation function\n",
    "\n",
    "for value in ['relu', 'tanh']:\n",
    "  res = create_and_train_model(activation_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4-Further experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
