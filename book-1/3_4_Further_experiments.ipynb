{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3lRQ--2Cum0",
    "outputId": "be0f27fd-3613-4a47-fd36-c46d48e3adf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/dados/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nBAe6xXsCxib"
   },
   "outputs": [],
   "source": [
    "# Encoding the integer sequences into a binary matrix\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1.\n",
    "  return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lPT3RJo7C8zp"
   },
   "outputs": [],
   "source": [
    "# also vectorize your labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J7AL6_o5DESD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def reset_random_seeds(SEED = 42):\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VNDjZ3V5DM97"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def create_and_train_model(hidden_layers=2,\n",
    "                           hidden_units=16, \n",
    "                           loss_function='binary_crossentropy',\n",
    "                           activation_function='relu'):\n",
    "  \n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Dense(hidden_units, activation=activation_function, input_shape=(10000,)))\n",
    "\n",
    "  for i in range(hidden_layers - 1):\n",
    "    model.add(layers.Dense(hidden_units, activation=activation_function))\n",
    " \n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss=loss_function,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train,\n",
    "            y_train,\n",
    "            epochs=4,\n",
    "            verbose=0,\n",
    "            batch_size=512)\n",
    "\n",
    "  results = model.evaluate(x_test, y_test)\n",
    "\n",
    "  return \"[hidden_layers=%d, hidden_units=%d, loss_function=%s, \" \\\n",
    "          \"activation_function=%s]\\n => loss: %.4f - accuracy: %.4f\\n\" % (\n",
    "          hidden_layers, hidden_units, loss_function, activation_function,\n",
    "          results[0], results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SmHGvWh6DQNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 584us/step - loss: 0.3036 - accuracy: 0.8776\n",
      "[hidden_layers=1, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3036 - accuracy: 0.8776\n",
      "\n",
      "782/782 [==============================] - 1s 576us/step - loss: 0.2860 - accuracy: 0.8868\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2860 - accuracy: 0.8868\n",
      "\n",
      "782/782 [==============================] - 1s 588us/step - loss: 0.3057 - accuracy: 0.8801\n",
      "[hidden_layers=3, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3057 - accuracy: 0.8801\n",
      "\n",
      "782/782 [==============================] - 1s 583us/step - loss: 0.3923 - accuracy: 0.8528\n",
      "[hidden_layers=4, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3923 - accuracy: 0.8528\n",
      "\n",
      "CPU times: user 55.4 s, sys: 5.07 s, total: 1min\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# You used two hidden layers. Try using one or three hidden layers, \n",
    "# and see how doing so affects validation and test accuracy.\n",
    "\n",
    "# => best result: 2 hidden layers\n",
    "\n",
    "for value in [1, 2, 3, 4]:\n",
    "  res = create_and_train_model(hidden_layers=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEHs9YwZDTHR",
    "outputId": "62383eec-b083-465d-fb18-c70dcad0b8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.8877\n",
      "[hidden_layers=2, hidden_units=4, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3040 - accuracy: 0.8877\n",
      "\n",
      "782/782 [==============================] - 1s 577us/step - loss: 0.2816 - accuracy: 0.8908\n",
      "[hidden_layers=2, hidden_units=8, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2816 - accuracy: 0.8908\n",
      "\n",
      "782/782 [==============================] - 1s 591us/step - loss: 0.3043 - accuracy: 0.8809\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3043 - accuracy: 0.8809\n",
      "\n",
      "782/782 [==============================] - 1s 557us/step - loss: 0.3242 - accuracy: 0.8758\n",
      "[hidden_layers=2, hidden_units=32, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3242 - accuracy: 0.8758\n",
      "\n",
      "CPU times: user 49.8 s, sys: 4.4 s, total: 54.2 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try using layers with more hidden units or fewer hidden units: \n",
    "# 32 units, 64 units, and so on.\n",
    "\n",
    "# => best result: 8 hidden units\n",
    "\n",
    "for value in [4, 8, 16, 32]:\n",
    "  res = create_and_train_model(hidden_units=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQog_ia8D_yM",
    "outputId": "3aac1a60-a5ae-4889-f350-0869fb20a214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 666us/step - loss: 0.3025 - accuracy: 0.8796\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.3025 - accuracy: 0.8796\n",
      "\n",
      "782/782 [==============================] - 4s 2ms/step - loss: 0.0858 - accuracy: 0.8842\n",
      "[hidden_layers=2, hidden_units=16, loss_function=mse, activation_function=relu]\n",
      " => loss: 0.0858 - accuracy: 0.8842\n",
      "\n",
      "CPU times: user 25 s, sys: 10.7 s, total: 35.7 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try using the mse loss function instead of binary_crossentropy.\n",
    "\n",
    "# => best result: mse loss function\n",
    "\n",
    "for value in ['binary_crossentropy', 'mse']:\n",
    "  res = create_and_train_model(loss_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PBCyLqaUEGXi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 597us/step - loss: 0.2978 - accuracy: 0.8818\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=relu]\n",
      " => loss: 0.2978 - accuracy: 0.8818\n",
      "\n",
      "782/782 [==============================] - 1s 593us/step - loss: 0.3150 - accuracy: 0.8808\n",
      "[hidden_layers=2, hidden_units=16, loss_function=binary_crossentropy, activation_function=tanh]\n",
      " => loss: 0.3150 - accuracy: 0.8808\n",
      "\n",
      "CPU times: user 32 s, sys: 3.07 s, total: 35.1 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try using the tanh activation (an activation that was popular in \n",
    "# the early days of neural networks) instead of relu.\n",
    "\n",
    "# => best result: relu activation function\n",
    "\n",
    "for value in ['relu', 'tanh']:\n",
    "  res = create_and_train_model(activation_function=value)\n",
    "  print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4-Further experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
